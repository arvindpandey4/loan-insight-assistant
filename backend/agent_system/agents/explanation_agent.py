import json
import os
from typing import List, Optional
from groq import Groq
from ..schemas import QueryIntentSchema, RetrievedLoanCaseSchema, FinalResponseSchema
from ..prompts import EXPLANATION_PROMPT, COMPLIANCE_GUIDELINES

class ExplanationAgent:
    def __init__(self, model_name: str = "llama-3.3-70b-versatile", api_key: Optional[str] = None):
        self.model_name = model_name
        self.api_key = api_key or os.getenv('GROQ_API_KEY')
        self.client = None
        if self.api_key:
            try:
                self.client = Groq(api_key=self.api_key)
            except Exception as e:
                print(f"[ERROR] Failed to initialize Groq client: {e}")
                self.client = None
        else:
            print("[WARN] Groq API Key missing. ExplanationAgent will use placeholder logic.")

    def generate_explanation(self, query: str, intent: QueryIntentSchema, cases: List[RetrievedLoanCaseSchema]) -> FinalResponseSchema:
        if not self.client or not cases:
            return self._generate_placeholder_response(query, intent, cases)

        # 1. Prepare context
        context_parts = []
        for i, case in enumerate(cases, 1):
            context_parts.append(f"Case {i}: Customer {case.customer_name}, Status: {case.approval_status}, Amount: INR {case.loan_amount}")
            # Add relevant metadata from original_data
            for key in ['Applicant_Income', 'CIBIL_Score', 'Debt_to_Income_Ratio', 'Loan_Purpose']:
                if key in case.original_data:
                    context_parts.append(f"  - {key}: {case.original_data[key]}")
        
        context_str = "\n".join(context_parts)

        # 2. Call LLM
        prompt = EXPLANATION_PROMPT.format(
            query=query,
            intent=intent.intent.value,
            tone=intent.compliance_tone.value,
            context=context_str,
            compliance_guidelines=COMPLIANCE_GUIDELINES
        )

        try:
            response = self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "You are a specialized Loan Compliance Analyst."},
                    {"role": "user", "content": prompt}
                ],
                model=self.model_name,
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            
            data = json.loads(response.choices[0].message.content)
            
            return FinalResponseSchema(
                query=query,
                intent=intent.intent,
                retrieved_case_count=len(cases),
                summary=data.get("summary", "Analysis complete."),
                evidence_points=data.get("evidence_points", []),
                risk_notes=data.get("risk_notes", []),
                compliance_disclaimer=data.get("compliance_disclaimer", "Generated by AI. Verify with official records."),
                structured_data=cases
            )

        except Exception as e:
            print(f"[ERROR] ExplanationAgent LLM Error: {e}")
            return self._generate_placeholder_response(query, intent, cases)

    def _generate_placeholder_response(self, query: str, intent: QueryIntentSchema, cases: List[RetrievedLoanCaseSchema]) -> FinalResponseSchema:
        if not cases:
            return FinalResponseSchema(
                query=query,
                intent=intent.intent,
                retrieved_case_count=0,
                summary="No relevant historical cases found matching your query.",
                evidence_points=[],
                risk_notes=["Try broadening your search criteria."],
                compliance_disclaimer="Generated by AI (Fallback Mode).",
                structured_data=[]
            )

        # Analyze cases manually
        total = len(cases)
        approved = sum(1 for c in cases if c.approval_status == 'Approved')
        rejected = total - approved
        approval_rate = (approved / total) * 100
        
        # Extract common patterns from original data (with safe type conversion)
        def safe_float(value, default=0):
            try:
                return float(value) if value else default
            except (ValueError, TypeError):
                return default
        
        avg_cibil = sum(safe_float(c.original_data.get('CIBIL_Score')) for c in cases) / total
        avg_income = sum(safe_float(c.original_data.get('Applicant_Income')) for c in cases) / total
        
        # Construct a rich summary
        summary = (
            f"Based on {total} similar historical case(s), the approval rate is {approval_rate:.1f}%. "
            f"The candidates had an average CIBIL score of {avg_cibil:.0f} and average income of INR {avg_income:,.0f}. "
            f"{'Most cases were rejected.' if rejected > approved else 'Most cases were approved.'}"
        )

        # Generate evidence points
        evidence_points = []
        for c in cases[:5]:
            status_icon = "âœ…" if c.approval_status == 'Approved' else "âŒ"
            evidence_points.append(
                f"{status_icon} Case: {c.customer_name} ({c.approval_status}) - CIBIL: {c.original_data.get('CIBIL_Score', 'N/A')}, Income: {c.original_data.get('Applicant_Income', 'N/A')}"
            )

        # Generate risk notes based on rejected cases
        risk_notes = []
        rejected_cases = [c for c in cases if c.approval_status == 'Rejected']
        if rejected_cases:
            risk_notes.append("Common factors in rejected cases:")
            # Check simple thresholds (heuritics)
            low_cibil = sum(1 for c in rejected_cases if safe_float(c.original_data.get('CIBIL_Score')) < 750)
            if low_cibil > 0:
                risk_notes.append(f"â€¢ Low CIBIL Score (<750) observed in {low_cibil} rejected cases.")
            
            high_loan = sum(1 for c in rejected_cases if safe_float(c.original_data.get('Loan_Amount')) > 5000000)
            if high_loan > 0:
                risk_notes.append(f"â€¢ High Loan Amount (>50L) observed in {high_loan} rejected cases.")
        else:
            risk_notes.append("No significant risk factors detected in the retrieved similar cases (mostly approved).")
        
        return FinalResponseSchema(
            query=query,
            intent=intent.intent,
            retrieved_case_count=len(cases),
            summary=summary,
            evidence_points=evidence_points,
            risk_notes=risk_notes,
            compliance_disclaimer="Generated by Case Analysis Engine (Fallback Mode). Verify with official records.",
            structured_data=cases
        )
